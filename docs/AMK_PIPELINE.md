---
title: AMK_PIPELINE — Amazing Korean Development Pipeline
updated: 2026-02-16
owner: HYMN Co., Ltd. (Amazing Korean)
audience: AI agents / lead / developer
---

## AMK_PIPELINE — Amazing Korean Development Pipeline

> 이 문서는 **멀티 AI 오케스트레이션 및 개발 작업 흐름의 기준 문서**이다.

> 규칙/스펙은 [`AMK_API_MASTER.md`](./AMK_API_MASTER.md), 배포/운영은 [`AMK_DEPLOY_OPS.md`](./AMK_DEPLOY_OPS.md)를 참조한다.

---

## 목차 (Table of Contents)

- [1. 개요 (Overview)](#1-개요-overview)
  - [1.1 목적과 범위](#11-목적과-범위)
  - [1.2 핵심 철학](#12-핵심-철학)
  - [1.3 용어 정의](#13-용어-정의)
  - [1.4 관련 문서](#14-관련-문서)
  - [1.5 도입 단계](#15-도입-단계)
- [2. 파이프라인 아키텍처 (Pipeline Architecture)](#2-파이프라인-아키텍처-pipeline-architecture)
  - [2.1 전체 작업 흐름도](#21-전체-작업-흐름도)
  - [2.2 단계별 정의](#22-단계별-정의)
  - [2.3 단계 간 전환 조건](#23-단계-간-전환-조건)
- [3. 역할 분리 (Role Separation)](#3-역할-분리-role-separation)
  - [3.1 역할의 두 가지 성격](#31-역할의-두-가지-성격)
  - [3.2 AI 모델별 역할 배치](#32-ai-모델별-역할-배치)
  - [3.3 기획 역할 운영 규칙](#33-기획-역할-운영-규칙)
  - [3.4 실행 역할 운영 규칙](#34-실행-역할-운영-규칙)
  - [3.5 창의적 이탈 처리](#35-창의적-이탈-처리)
  - [3.6 플랫폼별 역할 배치](#36-플랫폼별-역할-배치)
- [4. 작업 문서화 (Work Documentation)](#4-작업-문서화-work-documentation)
  - [4.1 작업 단위 정의](#41-작업-단위-정의)
  - [4.2 디렉터리 구조](#42-디렉터리-구조)
  - [4.3 태스크 파일 템플릿](#43-태스크-파일-템플릿)
  - [4.4 문서화 시점](#44-문서화-시점)
  - [4.5 세션 간 연속성 보장](#45-세션-간-연속성-보장)
- [5. 메신저 연동 (Messenger Integration)](#5-메신저-연동-messenger-integration)
  - [5.1 알림 대상 이벤트](#51-알림-대상-이벤트)
  - [5.2 연동 채널 및 우선순위](#52-연동-채널-및-우선순위)
  - [5.3 사용자 개입 요청](#53-사용자-개입-요청)
- [6. 샌드박스 환경 (Sandboxed Environment)](#6-샌드박스-환경-sandboxed-environment)
  - [6.1 격리 원칙](#61-격리-원칙)
  - [6.2 환경 구성](#62-환경-구성)
  - [6.3 안전장치](#63-안전장치)
- [7. 멀티 플랫폼 확장 (Multi-Platform Strategy)](#7-멀티-플랫폼-확장-multi-platform-strategy)
  - [7.1 현재 상태](#71-현재-상태)
  - [7.2 확장 계획](#72-확장-계획)
  - [7.3 플랫폼 간 공유 계층](#73-플랫폼-간-공유-계층)
  - [7.4 파이프라인 분기점](#74-파이프라인-분기점)
- [8. 품질 게이트 (Quality Gates)](#8-품질-게이트-quality-gates)
  - [8.1 단계별 게이트 정의](#81-단계별-게이트-정의)
  - [8.2 자동 vs 수동 검증](#82-자동-vs-수동-검증)
  - [8.3 실패 시 처리](#83-실패-시-처리)
- [9. 도구 선택 기준 (Tool Selection Criteria)](#9-도구-선택-기준-tool-selection-criteria)
  - [9.1 평가 기준](#91-평가-기준)
  - [9.2 후보 도구 평가](#92-후보-도구-평가)
  - [9.3 도구 교체 프로세스](#93-도구-교체-프로세스)
- [10. Git 브랜치 전략 (Git Branch Strategy)](#10-git-브랜치-전략-git-branch-strategy)
  - [10.1 개요](#101-개요)
  - [10.2 브랜치 모델](#102-브랜치-모델)
  - [10.3 단일 태스크 브랜치 흐름](#103-단일-태스크-브랜치-흐름)
  - [10.4 커밋 메시지 규칙](#104-커밋-메시지-규칙)
  - [10.5 단계별 문서화](#105-단계별-문서화)
  - [10.6 Phase 1 운영 (현행)](#106-phase-1-운영-현행)
- [11. 온디바이스 AI 전략 (On-Device AI Strategy)](#11-온디바이스-ai-전략-on-device-ai-strategy)
  - [11.1 개요와 목적](#111-개요와-목적)
  - [11.2 기술 스택](#112-기술-스택)
  - [11.3 Mac Mini 허브 아키텍처](#113-mac-mini-허브-아키텍처)
  - [11.4 파이프라인 연계](#114-파이프라인-연계)
  - [11.5 학습 콘텐츠 온디바이스 제공](#115-학습-콘텐츠-온디바이스-제공)
  - [11.6 콘텐츠 파이프라인](#116-콘텐츠-파이프라인)
  - [11.7 하이브리드 아키텍처 (온디바이스 + 서버)](#117-하이브리드-아키텍처-온디바이스--서버)
  - [11.8 도입 로드맵](#118-도입-로드맵)
  - [11.9 한국어 발음 교정 AI 오케스트레이션](#119-한국어-발음-교정-ai-오케스트레이션)

---

## 1. 개요 (Overview)

### 1.1 목적과 범위

이 문서는 Amazing Korean 프로젝트의 **개발 작업 흐름**과 **멀티 AI 오케스트레이션** 체계를 정의한다.

**다루는 것:**
- 기획부터 배포까지의 전체 작업 흐름
- AI 모델별 역할 배치 및 협업 규칙
- 작업 문서화, 메신저 연동, 샌드박스 환경
- 멀티 플랫폼 확장 시 파이프라인 분기

**다루지 않는 것:**
- 코드 스펙/규칙 → [`AMK_API_MASTER.md`](./AMK_API_MASTER.md)
- 배포/인프라 구현 → [`AMK_DEPLOY_OPS.md`](./AMK_DEPLOY_OPS.md)
- 코드 패턴/예시 → [`AMK_CODE_PATTERNS.md`](./AMK_CODE_PATTERNS.md)

### 1.2 핵심 철학

> **"도구가 파이프라인을 만드는 게 아니라, 파이프라인이 도구를 선택한다."**

파이프라인(작업 흐름)을 먼저 설계하고, 그 흐름에 맞는 도구를 선택한다.
특정 도구(Agent Teams, OpenClaw 등)에 종속되지 않는 구조를 유지한다.
도구가 바뀌어도 파이프라인은 그대로 작동해야 한다.

### 1.3 용어 정의

| 용어 | 정의 |
|------|------|
| **오케스트레이터** | 작업 흐름을 관리하고 AI들에게 작업을 배분하는 주체 (사용자 또는 도구) |
| **기획 역할** | "무엇을, 어떻게" 할지 사고하고 계획을 수립하는 AI의 역할 |
| **실행 역할** | 기획에서 확정된 지시를 받아 코드를 작성/테스트하는 AI의 역할 |
| **핸드오프** | 한 AI(또는 단계)에서 다음 AI(또는 단계)로 작업과 컨텍스트를 전달하는 행위 |
| **품질 게이트** | 다음 단계로 넘어가기 위해 반드시 통과해야 하는 검증 조건 |
| **샌드박스** | AI가 작업하는 격리된 실행 환경 (프로덕션과 분리) |
| **이탈 (Divergence)** | 기획 단계에서 프로젝트 방향과 다른 창의적 아이디어가 나오는 상황 |

### 1.4 관련 문서

| 문서 | 역할 | 관계 |
|------|------|------|
| [`AMK_API_MASTER.md`](./AMK_API_MASTER.md) | 규칙/스펙 (What) | 실행 단계에서 따르는 기준 |
| [`AMK_DEPLOY_OPS.md`](./AMK_DEPLOY_OPS.md) | 인프라/배포 (How to deploy) | 배포 단계의 기술 구현 |
| [`AMK_CODE_PATTERNS.md`](./AMK_CODE_PATTERNS.md) | 코드 패턴/예시 | 실행 단계에서 참조하는 코드 템플릿 |
| **AMK_PIPELINE.md** (본 문서) | 협업/작업 흐름 (How to work) | 전체 작업 흐름 및 AI 오케스트레이션 |

### 1.5 도입 단계

| 단계 | 상태 | 설명 |
|------|------|------|
| Phase 1 | 현재 | 1인 개발 + 단일 AI (Claude Code). 이 문서를 기준으로 작업 흐름 정립 |
| Phase 2 | 계획 | 멀티 AI 도입 (Claude + Gemini/ChatGPT). 역할 분리 적용 |
| Phase 3 | 계획 | 풀 오케스트레이션. 메신저 연동, 자동 핸드오프, 샌드박스 환경 운영 |
| Phase 4 | 계획 | 온디바이스 AI. Mac Mini 허브 + 로컬 LLM + 모바일 온디바이스 AI (§11 참조) |

[맨 위로](#목차-table-of-contents)

---

## 2. 파이프라인 아키텍처 (Pipeline Architecture)

### 2.1 전체 작업 흐름도

| 순서 | 단계 | 영문 | 주체 | 핵심 활동 |
|:----:|------|------|------|----------|
| 1 | **기획** | Planning | 기획 AI (복수 모델) | 요구사항 분석, 기술 설계, 구현 계획 수립 |
| 2 | **검증** | Verify | 기획 AI (교차 검증) | 기획 타당성 검증, 누락/모순 확인, 대안 제시 |
| 3 | **지시** | Directive | **사용자** (최종 결정) | 기획 승인, 실행 범위 확정, 작업 지시 |
| 4 | **실행** | Execute | 실행 AI (코드 작성) | 코드 작성, 단위 테스트, 문서 동기화 |
| 5 | **리뷰** | Review | 기획 AI (코드 리뷰) | 코드 리뷰, 기획 대비 완성도 확인 |
| 6 | **QA** | QA Test | 실행 AI + 사용자 | 기능 테스트, 스모크 테스트, 버그 리포트 |
| 7 | **배포** | Deploy | CI/CD (자동 배포) | 빌드, 배포, 프로덕션 반영 |

> **흐름:** 기획 → 검증 → 지시 → 실행 → 리뷰 → QA → 배포
> **반복 가능:** 1↔2 (기획/검증), 4↔5 (실행/리뷰), 5↔6 (리뷰/QA)

### 2.2 단계별 정의

#### 1단계: 기획 (Planning)

| 항목 | 내용 |
|------|------|
| **주체** | 기획 역할 AI (복수 모델 가능) |
| **입력** | 사용자 요구사항, 기존 문서/코드 |
| **활동** | 요구사항 분석, 기술 설계, 구현 계획 수립 |
| **출력** | 기획 문서 (목표, 접근 방식, 변경 파일 목록, 예상 영향 범위) |

#### 2단계: 검증 (Verify)

| 항목 | 내용 |
|------|------|
| **주체** | 기획 역할 AI (기획과 다른 모델 권장) |
| **입력** | 1단계 기획 문서 |
| **활동** | 기획의 타당성 검증, 누락/모순 확인, 대안 제시 |
| **출력** | 검증 리포트 (승인/수정 요청/대안) |

> 사용자가 충분하다고 판단할 때까지 1-2단계를 반복할 수 있다.
> 사이클 종료 시점은 **사용자가 직접 결정**한다.

#### 3단계: 지시 (Directive)

| 항목 | 내용 |
|------|------|
| **주체** | **사용자** (유일한 지시 주체) |
| **입력** | 검증 완료된 기획 문서 |
| **활동** | 기획 승인, 실행 범위 확정, 작업 지시 |
| **출력** | 확정된 작업 지시서 |

> 이 단계는 반드시 사용자가 개입한다. AI가 스스로 실행 단계로 넘어가지 않는다.

#### 4단계: 실행 (Execute)

| 항목 | 내용 |
|------|------|
| **주체** | 실행 역할 AI |
| **입력** | 확정된 작업 지시서 |
| **활동** | 코드 작성, 테스트, 문서 동기화 |
| **출력** | 구현 완료된 코드 + 테스트 결과 |
| **참조** | 개별 작업 절차 → [`AMK_API_MASTER.md 7.2`](./AMK_API_MASTER.md#72-개발-플로우) |

#### 5단계: 리뷰 (Review)

| 항목 | 내용 |
|------|------|
| **주체** | 기획 역할 AI + 사용자 |
| **입력** | 실행 결과물 (코드, 테스트, 문서) |
| **활동** | 코드 리뷰, 기획 대비 완성도 확인, 문서 동기화 확인 |
| **출력** | 리뷰 리포트 (승인/수정 요청) |

#### 6단계: QA (QA Test)

| 항목 | 내용 |
|------|------|
| **주체** | 실행 역할 AI + 사용자 |
| **입력** | 리뷰 승인된 코드 |
| **활동** | 기능 테스트, 스모크 테스트, 브라우저 테스트, 버그 리포트 작성 |
| **출력** | QA 리포트 (통과/버그 목록) |
| **참조** | 테스트 기준 → [`AMK_API_MASTER.md 7.6`](./AMK_API_MASTER.md#76-테스트--자동화), 스모크 체크 → [`AMK_DEPLOY_OPS.md 7`](./AMK_DEPLOY_OPS.md#7-품질-보증--스모크-체크) |

> QA에서 버그가 발견되면 실행 단계(4)로 돌아가 수정 후 다시 리뷰(5) → QA(6)를 거친다.

#### 7단계: 배포 (Deploy)

| 항목 | 내용 |
|------|------|
| **주체** | CI/CD 자동화 + 사용자 승인 |
| **입력** | QA 통과된 코드 |
| **활동** | 빌드, 배포, 프로덕션 반영 |
| **출력** | 프로덕션 반영 |
| **참조** | 기술 구현 → [`AMK_DEPLOY_OPS.md 5`](./AMK_DEPLOY_OPS.md#5-github-actions-cicd-파이프라인) |

### 2.3 단계 간 전환 조건

| 순서 | 전환 | 조건 | 결정권자 |
|-----|------|------|----------|
| 1 | 기획 → 검증 | 기획 문서 작성 완료 | 기획 AI |
| 2 | 검증 → 기획 (반복) | 검증에서 문제 발견 | 기획 AI / 사용자 |
| 3 | 검증 → 지시 | 검증 통과 + 사용자 승인 | **사용자** |
| 4 | 지시 → 실행 | 사용자가 작업 지시 | **사용자** |
| 5 | 실행 → 리뷰 | 구현 완료 + 빌드/테스트 통과 | 실행 AI |
| 6 | 리뷰 → 실행 (반복) | 구현 검증에서 문제점 발견 시 수정 | 실행 AI / 사용자 |
| 7 | 리뷰 → QA | 코드 리뷰 승인 | 기획 AI / 사용자 |
| 8 | QA → 실행 (반복) | QA에서 문제점 발견 시 수정 | 실행 AI / 사용자 |
| 9 | QA → 배포 | QA 통과 + 사용자 승인 | **사용자** |
| 10 | 배포 → 실행 (반복) | 배포에서 문제점 발견 시 수정 | 실행 AI / 사용자  |

[맨 위로](#목차-table-of-contents)

---

## 3. 역할 분리 (Role Separation)

### 3.1 역할의 두 가지 성격

역할은 **일의 성격**에 따라 구분한다. 권한이나 위계가 아니다.

| 성격 | 하는 일 | 사고 방식 |
|------|---------|----------|
| **기획 (Planning)** | 무엇을, 어떻게 할지 결정 | 분석, 설계, 검증, 대안 탐색 |
| **실행 (Execution)** | 확정된 지시를 구현 | 코드 작성, 테스트, 문서 동기화 |

하나의 AI 모델이 두 역할을 겸할 수 있지만, **동시에 수행하지 않는다**.
기획 중에는 기획만, 실행 중에는 실행만 한다.

### 3.2 AI 모델별 역할 배치

> 아래는 초기 배치안이며, 프로젝트 진행에 따라 조정한다.

| AI 모델 | 주 역할 | 강점 | 비고 |
|---------|---------|------|------|
| **Claude** | 기획 + 실행 | 코드 품질, 문서화, 장문 컨텍스트 | 현재 주력 (Phase 1) |
| **Gemini** | 기획 (교차 검증) | 다양한 시각, 빠른 탐색 | Phase 2에서 도입 예정 |
| **ChatGPT** | 기획 (교차 검증) | 창의적 대안, 사용자 관점 | Phase 2에서 도입 예정 |

**모델 배치 원칙:**
- 기획 단계에서는 **복수 모델**을 활용하여 계획을 교차 검증한다
- 실행 단계에서는 **단일 모델**이 일관성 있게 작업한다
- 모델별 강점에 따라 역할을 배치하되, 특정 모델에 종속되지 않는다

### 3.3 기획 역할 운영 규칙

1. 기획 AI는 요구사항을 분석하고 **구현 계획을 문서로 출력**한다
2. 계획에는 반드시 포함: 목표, 접근 방식, 변경 파일 목록, 예상 영향 범위
3. 복수 AI를 사용할 경우, 각 AI가 **독립적으로** 계획을 검증한다
4. 검증 결과가 다를 경우, 차이점을 문서화하여 사용자에게 제시한다
5. 기획/검증 사이클의 종료는 **사용자가 직접 판단**한다

### 3.4 실행 역할 운영 규칙

1. 실행 AI는 **확정된 지시서만** 받아 작업한다
2. 지시 범위를 벗어나는 작업은 수행하지 않는다
3. 코드 작성 시 [`AMK_API_MASTER.md 0.4`](./AMK_API_MASTER.md#04-ai-에이전트-협업-규칙)의 공통 규칙을 따른다
4. 실행 중 예상치 못한 문제 발견 시, 작업을 중단하고 보고한다 (자의적 판단으로 범위를 확장하지 않는다)
5. 실행 완료 후 결과물을 문서화한다 (변경 사항, 테스트 결과, 주의점)

### 3.5 창의적 이탈 처리

기획 단계에서 프로젝트 방향과 다른 창의적 아이디어가 나올 수 있다.
이를 버리지 않고 **별도 문서로 기록**한다.

**이탈 기록 필수 항목:**

| 항목 | 설명 |
|------|------|
| **언제 (When)** | 어떤 기획 단계에서 발생했는지 |
| **누가 (Who)** | 어떤 AI 모델이 제안했는지 |
| **무엇을 (What)** | 아이디어의 핵심 내용 |
| **어떻게 (How)** | 구현 방법 (간략) |
| **왜 (Why)** | 왜 이 아이디어가 나왔는지, 기대 효과 |

> 실행 단계에서는 창의적 이탈이 구조적으로 발생하기 어렵다.
> 실행 AI는 지시된 작업만 수행하도록 설계되어 있기 때문이다.

### 3.6 플랫폼별 역할 배치

> Phase 2 이후, 멀티 플랫폼 확장 시 적용한다.

| 플랫폼 | 실행 AI | 기획 AI |
|--------|---------|---------|
| Web (React + Rust API) | Claude | 공유 |
| Android (스택 TBD) | TBD | 공유 |
| iOS (스택 TBD) | TBD | 공유 |

**원칙:** 기획은 플랫폼 간 **공유** (비즈니스 로직은 동일), 실행은 플랫폼별 **전담**.

[맨 위로](#목차-table-of-contents)

---

## 4. 작업 문서화 (Work Documentation)

### 4.1 작업 단위 정의

| 단위 | 규모 | 예시 | 문서 위치 |
|------|------|------|----------|
| **에픽 (Epic)** | 대규모 기능 | "결제 시스템 구축", "다국어 콘텐츠 확장" | `docs/epics/{epic-name}/` 폴더 |
| **태스크 (Task)** | 하나의 작업 세션에서 완료 가능한 단위 | "Stripe Webhook 처리 구현", "이메일 인증 시스템" | `docs/epics/{epic-name}/T{NNN}_{task-name}.md` 파일 |
| **서브태스크 (Subtask)** | 태스크 내 개별 작업 항목 | "결제 DTO 정의", "Webhook 라우터 추가" | 태스크 파일 내 체크리스트 |

### 4.2 디렉터리 구조

```
docs/epics/
├── payment-system/                         # Epic 폴더
│   ├── T001_stripe-webhook.md              # Task 파일
│   ├── T002_subscription-model.md
│   └── T003_payment-ui.md
├── i18n-multilingual/
│   ├── T001_db-schema.md
│   └── T002_translation-api.md
└── email-verification/                     # 완료된 Epic도 보관
    ├── T001_email-sender-trait.md
    └── T002_frontend-verify-page.md
```

**네이밍 규칙:**
- Epic 폴더: `kebab-case` (소문자, 하이픈 구분)
- Task 파일: `T{NNN}_{kebab-case}.md` (NNN은 3자리 순번)
- 순번은 Epic 내에서 생성 순서 (재정렬하지 않음)

### 4.3 태스크 파일 템플릿

```markdown
# T001: Stripe Webhook 처리 구현

## 메타
| 항목 | 값 |
|------|-----|
| Epic | 결제 시스템 |
| 상태 | 대기 / 진행 중 / 리뷰 / QA / 완료 |
| 담당 | Claude (실행) |
| 생성일 | 2026-02-10 |
| 완료일 | - |

## 컨텍스트
왜 이 작업이 필요한지, 배경 설명

## 결정 사항
- 어떤 기술적 결정을 내렸고 왜

## Subtasks
- [ ] Webhook DTO 정의
- [ ] 라우터 추가
- [ ] 서명 검증 로직
- [ ] 에러 핸들링

## 변경 이력
| 파일 | 변경 내용 |
|------|----------|
| `src/api/payment/handler.rs` | Webhook 엔드포인트 추가 |
| `src/api/payment/dto.rs` | StripeEvent DTO 정의 |

## 테스트 결과
- `cargo check`: PASS
- `npm run build`: PASS

## 주의점
후속 작업 시 알아야 할 사항
```

### 4.4 문서화 시점

| 파이프라인 단계 | 기록 항목 | 담당 |
|---------------|----------|------|
| 기획 (1) | 메타, 컨텍스트, 초기 Subtasks | 기획 AI |
| 검증 (2) | 결정 사항 (검증 과정에서 확정된 내용) | 기획 AI |
| 실행 (4) | 변경 이력, Subtask 체크, 테스트 결과 | 실행 AI |
| 리뷰 (5) | 주의점, 리뷰 피드백 반영 내용 | 기획 AI |
| QA (6) | QA 결과 (통과/버그 목록) | 실행 AI + 사용자 |
| 배포 (7) | 상태를 "완료"로 변경, 완료일 기록 | 실행 AI |

### 4.5 세션 간 연속성 보장

| 도구 | 역할 | 갱신 시점 |
|------|------|----------|
| `docs/epics/` | 작업 상세 기록 (Epic/Task/Subtask) | 매 파이프라인 단계마다 |
| `MEMORY.md` (에이전트 메모리) | 세션 간 요약/참조. 완료/대기 작업 목록 | 매 세션 종료 시 |
| `CLAUDE.md` (프로젝트 루트) | 매 세션 자동 로딩. 프로젝트 구조, 핵심 규칙 | 구조적 변경 시 |
| `docs/AMK_API_MASTER.md` | 스펙/규칙의 SSoT | 스펙 변경 시 |
| `docs/AMK_DEPLOY_OPS.md` | 배포/운영 가이드 | 인프라 변경 시 |

**역할 분리:**
- `docs/epics/` = **상세 기록** (모든 컨텍스트, 결정 사항, 변경 이력)
- `MEMORY.md` = **요약/참조** (어떤 Epic이 진행 중인지, 핵심 포인트만)

**원칙:** 새 세션에서 작업을 이어받는 AI는 `MEMORY.md` → 해당 Epic/Task 파일 순서로 읽으면 컨텍스트를 완전히 파악할 수 있어야 한다.

[맨 위로](#목차-table-of-contents)

---

## 5. 메신저 연동 (Messenger Integration)

### 5.1 알림 대상 이벤트

| 이벤트 | 우선순위 | 설명 |
|--------|----------|------|
| 빌드 실패 | **높음** | CI/CD 빌드 또는 테스트 실패 |
| 배포 완료 | 보통 | 프로덕션 배포 성공 |
| 리뷰 완료 | 보통 | 코드 리뷰 결과 도착 |
| 승인 대기 | **높음** | 사용자 의사결정이 필요한 시점 |
| 기획 검증 완료 | 보통 | 기획/검증 사이클 결과 |
| 장애 감지 | **긴급** | 프로덕션 서비스 이상 |

### 5.2 연동 채널 및 우선순위

| 채널 | 용도 | 상태 |
|------|------|------|
| Slack / Discord | 개발 알림 (빌드, 배포, 리뷰) | 후보 |
| Telegram | 긴급 알림 (장애, 승인 대기) | 후보 |
| GitHub Notifications | PR/Issue 기반 알림 | 현재 사용 가능 |

> 채널 선정은 Phase 2 도입 시 확정한다.

### 5.3 사용자 개입 요청

AI가 사용자 개입이 필요한 상황:

1. **기획 → 지시 전환**: 기획/검증 완료 후 사용자 승인 대기
2. **의사결정 분기**: 복수 방안 중 선택이 필요할 때
3. **예외 상황**: 실행 중 예상치 못한 문제 발생

알림 포맷:
```
[AMK] 승인 대기: [태스크 이름]
- 상태: 기획 검증 완료
- 필요 액션: 실행 지시 또는 수정 요청
- 상세: [링크]
```

[맨 위로](#목차-table-of-contents)

---

## 6. 샌드박스 환경 (Sandboxed Environment)

### 6.1 격리 원칙

- AI는 **격리된 환경**에서만 코드를 실행한다
- 프로덕션 환경에 **직접 접근하지 않는다**
- 각 AI의 작업 환경은 **독립적**이다 (다른 AI의 작업에 영향을 주지 않음)

### 6.2 환경 구성

| 환경 | 용도 | 격리 수준 |
|------|------|----------|
| **개발 (dev)** | AI가 코드를 작성하고 테스트 | Docker 컨테이너 (로컬) |
| **스테이징 (staging)** | 배포 전 통합 테스트 | 별도 Docker Compose 환경 |
| **프로덕션 (prod)** | 실제 서비스 | EC2 (AI 직접 접근 불가) |

**AI별 환경 분리 (Phase 2 이후):**
```
┌─────────────────────────────────┐
│         공유 리소스               │
│  (Git repo, 문서, 설정 파일)      │
├─────────────┬───────────────────┤
│  AI-A 컨테이너  │  AI-B 컨테이너    │
│  (실행 역할)    │  (실행 역할)      │
│  독립 DB/Redis  │  독립 DB/Redis   │
└─────────────┴───────────────────┘
```

### 6.3 안전장치

| 안전장치 | 설명 |
|----------|------|
| **프로덕션 접근 차단** | AI 환경에서 프로덕션 DB/서버 접근 불가 |
| **파괴적 명령 방지** | `rm -rf`, `DROP DATABASE`, `force push` 등 차단 또는 확인 요구 |
| **환경 변수 분리** | `.env` (dev), `.env.prod` (prod) 분리. AI는 `.env`만 접근 |
| **네트워크 격리** | AI 컨테이너는 외부 네트워크 접근 제한 (필요한 API만 허용) |
| **작업 범위 제한** | 실행 AI는 지시된 파일/디렉터리만 수정 가능 |

[맨 위로](#목차-table-of-contents)

---

## 7. 멀티 플랫폼 확장 (Multi-Platform Strategy)

### 7.1 현재 상태

| 구성 요소 | 기술 스택 | 상태 |
|----------|----------|------|
| 백엔드 API | Rust + Axum + SQLx + PostgreSQL + Redis | 운영 중 |
| 프론트엔드 (Web) | React + Vite + TypeScript + shadcn/ui | 운영 중 |
| 모바일 (Android) | - | 미착수 |
| 모바일 (iOS) | - | 미착수 |

### 7.2 확장 계획

| 플랫폼 | 기술 스택 | 빌드 환경 | 비고 |
|--------|----------|----------|------|
| Android | TBD | TBD | - |
| iOS | TBD | **Mac (필수)** | Mac Mini 필요 |
| 온디바이스 AI | BitNet.cpp / Ollama | Mac Mini (개발/검증) → 모바일 배포 | §11 참조 |

### 7.3 플랫폼 간 공유 계층

```
┌──────────────────────────────────────┐
│           백엔드 API (Rust)            │  ← 모든 플랫폼 공유
├──────────────────────────────────────┤
│         비즈니스 로직 / 스펙            │  ← AMK_API_MASTER.md
├────────────┬────────────┬────────────┤
│  Web       │  Android   │  iOS       │  ← 플랫폼별 UI
│  (React)   │  (TBD)     │  (TBD)     │
└────────────┴────────────┴────────────┘
```

**공유되는 것:** API 엔드포인트, 데이터 모델, 인증 흐름, 비즈니스 규칙
**공유되지 않는 것:** UI 컴포넌트, 플랫폼별 네이티브 기능, 빌드/배포 설정

### 7.4 파이프라인 분기점

멀티 플랫폼 시, 파이프라인은 다음 지점에서 분기한다:

| 단계 | 공유/분기 | 설명 |
|------|----------|------|
| 기획 | **공유** | 비즈니스 로직은 플랫폼 무관 |
| 검증 | **공유** | API 스펙 검증은 한 번만 |
| 지시 | **분기** | 플랫폼별 실행 지시 |
| 실행 | **분기** | 플랫폼별 AI가 독립 실행 |
| 리뷰 | **분기 + 통합** | 플랫폼별 리뷰 후, API 호환성 통합 확인 |
| QA | **분기** | 플랫폼별 기능 테스트 |
| 배포 | **분기** | 플랫폼별 배포 파이프라인 |

[맨 위로](#목차-table-of-contents)

---

## 8. 품질 게이트 (Quality Gates)

### 8.1 단계별 게이트 정의

| 단계 전환 | 게이트 | 설명 |
|----------|--------|------|
| 기획 → 검증 | 기획 문서 완성도 | 목표, 접근 방식, 변경 파일, 영향 범위 포함 여부 |
| 검증 → 지시 | 검증 통과 | 교차 검증에서 심각한 문제 없음 + 사용자 승인 |
| 실행 → 리뷰 | 빌드/테스트 통과 | 정적 가드 + 빌드 성공 |
| 리뷰 → QA | 리뷰 승인 | 코드 리뷰 통과 + 문서 동기화 확인 |
| QA → 배포 | QA 통과 | 기능 테스트 + 스모크 테스트 통과 + 사용자 승인 |

### 8.2 자동 vs 수동 검증

| 구분 | 항목 | 담당 |
|------|------|------|
| **자동** | `cargo check`, `cargo clippy`, `cargo fmt` | CI / 실행 AI |
| **자동** | `npm run build` (프론트엔드) | CI / 실행 AI |
| **자동** | 빌드 성공 여부 | CI |
| **수동** | 기획 문서 검토 | 기획 AI + 사용자 |
| **수동** | 코드 리뷰 | 기획 AI + 사용자 |
| **수동/자동** | 기능 테스트 (QA) | 실행 AI + 사용자 |
| **수동** | 스모크 테스트 (QA) | 사용자 |
| **수동** | 브라우저 테스트 (QA) | 사용자 |

> 테스트 기준/목표치 → [`AMK_API_MASTER.md 7.6, 8.4`](./AMK_API_MASTER.md#76-테스트--자동화) 참조
> 배포 시 체크리스트 → [`AMK_DEPLOY_OPS.md 7`](./AMK_DEPLOY_OPS.md#7-품질-보증--스모크-체크) 참조

### 8.3 실패 시 처리

| 실패 유형 | 처리 |
|----------|------|
| 빌드/테스트 실패 | 실행 단계(4)로 돌아가 수정 |
| 코드 리뷰 수정 요청 | 실행 단계(4)로 돌아가 수정 후 재리뷰 |
| QA 버그 발견 | 실행 단계(4)로 돌아가 수정 후 리뷰(5) → QA(6) 재진행 |
| 기획 검증 실패 | 기획 단계(1)로 돌아가 재설계 |
| 배포 실패 | 롤백 후 원인 분석 → 실행 단계(4)로 |

**원칙:** 실패 시 항상 **이전 단계로 돌아간다**. 게이트를 우회하지 않는다.

[맨 위로](#목차-table-of-contents)

---

## 9. 도구 선택 기준 (Tool Selection Criteria)

### 9.1 평가 기준

도구를 선택할 때 다음 기준으로 평가한다:

| 기준 | 설명 | 가중치 |
|------|------|--------|
| **파이프라인 적합성** | 우리 작업 흐름에 자연스럽게 맞는가? | 높음 |
| **도구 독립성** | 특정 도구에 종속되지 않는 구조를 유지할 수 있는가? | 높음 |
| **안정성** | 프로덕션 수준의 안정성이 있는가? (실험적 기능 주의) | 높음 |
| **통합 용이성** | 기존 도구/워크플로우와 쉽게 연동되는가? | 보통 |
| **비용** | 합리적인 비용인가? | 보통 |
| **확장성** | 멀티 플랫폼/멀티 AI 확장 시에도 사용 가능한가? | 보통 |

### 9.2 후보 도구 평가

| 도구 | 용도 | 평가 | 상태 |
|------|------|------|------|
| **Claude Code** | AI 코딩 에이전트 | 파이프라인 적합, 안정적 | 현재 사용 |
| **GitHub Actions** | CI/CD | 파이프라인 적합, 안정적 | 현재 사용 |
| **Docker** | 환경 격리 | 파이프라인 적합, 안정적 | 현재 사용 |
| **Agent Teams** | 멀티 AI 오케스트레이션 | 파이프라인 적합, **실험적 기능** | 관찰 중 |
| **OpenClaw** | 멀티 AI 오케스트레이션 + 메신저 연동 | 파이프라인 적합, 통합 용이 | 평가 예정 |
| **Ollama** | 로컬 LLM 추론 (양자화 모델) | GPU+CPU 활용, 모델 다양, 안정적 | 평가 예정 (§11) |
| **BitNet.cpp** | 로컬 LLM 추론 (1비트 모델) | CPU 전용, 초경량, 온디바이스 배포 적합 | 평가 예정 (§11) |

> 현재 사용 중인 도구 목록 → [`AMK_DEPLOY_OPS.md 9`](./AMK_DEPLOY_OPS.md#9-운영-도구-목록) 참조

### 9.3 도구 교체 프로세스

1. **필요성 확인**: 현재 도구로 해결할 수 없는 문제가 있는가?
2. **후보 조사**: 9.1의 평가 기준으로 후보 도구를 비교
3. **PoC 테스트**: 작은 범위에서 후보 도구를 시험 적용
4. **의사결정**: 사용자가 도입 여부를 최종 결정
5. **점진적 도입**: 기존 도구와 병행 운영 후 전환
6. **문서 업데이트**: PIPELINE, DEPLOY_OPS 문서 동기화

**원칙:** 도구 교체는 항상 **점진적**으로 한다. 한 번에 전면 교체하지 않는다.

[맨 위로](#목차-table-of-contents)

---

## 10. Git 브랜치 전략 (Git Branch Strategy)

### 10.1 개요

> **Phase 2 (멀티 AI)부터 적용한다.** Phase 1에서는 [10.6](#106-phase-1-운영-현행) 참조.

파이프라인의 각 단계(기획, 실행, 리뷰 등)를 **Git 브랜치로 구조화**한다.
단계 간 핸드오프를 문서 전달이 아닌 **PR(Pull Request)**로 수행하여:

- 역할 분리가 **구조적으로 강제**된다 (각 AI는 자기 브랜치에서만 작업)
- 핸드오프가 **PR로 명시**된다 (누가 무엇을 넘겼는지 히스토리 보존)
- 단계별 품질 게이트가 **PR 승인으로 작동**한다
- 감사 추적(Audit Trail)이 **Git 히스토리에 완전 기록**된다

### 10.2 브랜치 모델

| 브랜치 | 용도 | 생성 시점 | 담당 |
|--------|------|----------|------|
| `main` | 프로덕션 코드. QA 통과 + 배포 완료된 코드만 존재 | 고정 | - |
| `plan/{TXXX}-{task}` | 기획 단계 작업. 기획 문서 작성 | 기획 시작 시 (main에서 분기) | 기획 AI |
| `verify/{TXXX}-{task}` | 검증 단계 작업. 검증 리포트 작성 | 검증 시작 시 (plan에서 분기) | 검증 AI |
| `exec/{TXXX}-{task}` | 실행 단계 작업. 코드 구현 | 지시 확정 후 (verify에서 분기) | 실행 AI |
| `hotfix/{설명}` | 긴급 프로덕션 버그 수정 | 장애 발생 시 (main에서 분기) | 실행 AI |

**브랜치 네이밍 규칙:**
- `{TXXX}`: 태스크 번호 (예: `T001`, `T002`)
- `{task}`: 태스크 이름 kebab-case (예: `stripe-webhook`, `i18n-frontend`)
- 예시: `plan/T001-stripe-webhook`, `exec/T001-stripe-webhook`

### 10.3 단일 태스크 브랜치 흐름

하나의 태스크(T001)가 파이프라인을 통과하는 전체 흐름:

```
main ──────────────────────────────────────────────────────── merge ←
  │                                                              │
  └─ plan/T001-stripe-webhook                                    │
       │  (기획 AI: 계획 문서 작성)                                  │
       │  → PR #1 생성 → 사용자 검토                                │
       │                                                         │
       └─ verify/T001-stripe-webhook                             │
            │  (검증 AI: 검증 리포트 작성)                           │
            │  → PR #2 생성 → 사용자 승인 (= 지시 단계)              │
            │                                                    │
            └─ exec/T001-stripe-webhook                          │
                 │  (실행 AI: 코드 구현)                            │
                 │  → PR #3 생성                                  │
                 │  → 리뷰 AI: PR에서 코드 리뷰                     │
                 │  → QA: PR 브랜치에서 테스트                       │
                 │  → 사용자 최종 승인                               │
                 └──────────────────────────────────────────────→─┘
```

**단계별 핸드오프:**

| 전환 | 방법 | PR 대상 |
|------|------|---------|
| 기획 → 검증 | `plan/` 브랜치에서 PR 생성 | 검증 AI가 리뷰 |
| 검증 → 지시 | 검증 완료 PR에 사용자가 승인 | 사용자 결정 |
| 지시 → 실행 | `exec/` 브랜치 생성, 사용자 지시 확정 | 실행 AI 시작 |
| 실행 → 리뷰 | `exec/` 브랜치에서 main 대상 PR 생성 | 리뷰 AI가 PR에서 코드 리뷰 |
| 리뷰 → QA | 리뷰 승인 후 QA 진행 | PR 브랜치에서 테스트 |
| QA → 배포 | QA 통과 + 사용자 승인 → main merge | CI/CD 자동 배포 |

### 10.4 커밋 메시지 규칙

**형식:**

```
[Stage] TXXX: 태스크명 - 설명
```

**단계별 예시 (T001: Stripe Webhook 처리):**

| 단계 | 커밋 메시지 예시 |
|------|-----------------|
| 기획 | `[Plan] T001: Stripe Webhook 처리 - plan formulation completed` |
| 검증 | `[Verify] T001: Stripe Webhook 처리 - plan verification completed` |
| 지시 | `[Directive] T001: Stripe Webhook 처리 - 실행 승인 및 범위 확정` |
| 실행 | `[Exec] T001: Stripe Webhook 처리 - code implementation completed` |
| 리뷰 | `[Review] T001: Stripe Webhook 처리 - code review completed` |
| QA | `[QA] T001: Stripe Webhook 처리 - QA test completed` |
| 배포 | `[Deploy] T001: Stripe Webhook 처리 - deployment complete` |

**규칙:**
- `[Stage]` 접두사는 영문 대문자 (Git log 필터링 용도)
- 태스크명은 **한국어 허용** (가독성 우선)
- Directive(지시) 단계는 **사용자가 한국어로 작성**
- 하나의 브랜치에 복수 커밋 가능 (작업 중간 커밋은 접두사 없이 자유)
- **최종 커밋**(PR 생성 직전)에 위 형식을 적용

### 10.5 단계별 문서화

각 파이프라인 단계는 **별도 파일**로 산출물을 생성한다.
이전 단계의 파일은 **읽기만** 하고 수정하지 않는다.

**디렉터리 구조:**

```
docs/epics/{epic-name}/
└── T001_stripe-webhook/              # 태스크 폴더
    ├── 01_plan.md                    # 기획 AI 산출물
    ├── 02_verify.md                  # 검증 AI 산출물
    ├── 03_directive.md               # 사용자 승인/지시 기록
    ├── 04_execute.md                 # 실행 AI 산출물 (변경 이력, 테스트 결과)
    ├── 05_review.md                  # 리뷰 AI 산출물 (리뷰 피드백)
    ├── 06_qa.md                      # QA 결과 (테스트 계획, 내역, 결과)
    └── 07_deploy.md                  # 배포 결과 (배포 내역, 확인 사항)
```

**원칙:**
- 각 AI는 **자기 번호의 파일만 생성**한다
- 이전 단계 파일을 **참조(읽기)**하되 **수정하지 않는다**
- 파일이 별도이므로 **브랜치 간 merge conflict가 발생하지 않는다**
- 기존 4.3절 태스크 파일 템플릿은 Phase 1용으로 유지하며, Phase 2부터 이 구조로 전환한다

**브랜치와 문서의 매핑:**

| 브랜치 | 생성하는 파일 | 참조하는 파일 |
|--------|-------------|-------------|
| `plan/` | `01_plan.md` | - |
| `verify/` | `02_verify.md` | `01_plan.md` |
| (지시 단계) | `03_directive.md` | `01_plan.md`, `02_verify.md` |
| `exec/` | `04_execute.md` | `01_plan.md`, `02_verify.md`, `03_directive.md` |
| (PR 리뷰) | `05_review.md` | `04_execute.md` |
| (QA) | `06_qa.md` | `04_execute.md`, `05_review.md` |
| (배포 후) | `07_deploy.md` | 전체 |

### 10.6 Phase 1 운영 (현행)

Phase 1 (1인 개발 + 단일 AI)에서는 **단순화된 브랜치 전략**을 사용한다.

| 항목 | Phase 1 (현행) | Phase 2 (전환 후) |
|------|---------------|-----------------|
| 브랜치 모델 | `main` + 작업 브랜치 1개 | `main` + 단계별 브랜치 |
| 핸드오프 | 문서 기반 (세션 간 `MEMORY.md`) | PR 기반 |
| 문서화 | 단일 태스크 파일 (4.3절 템플릿) | 단계별 별도 파일 (10.5절) |
| 커밋 메시지 | `Phase V1-2 : 작업 내용` | `[Stage] TXXX: 태스크명 - 설명` |

> Phase 2 전환 시, 기존 완료된 태스크는 변환하지 않는다. 새 태스크부터 적용한다.

[맨 위로](#목차-table-of-contents)

---

## 11. 온디바이스 AI 전략 (On-Device AI Strategy)

### 11.1 개요와 목적

Amazing Korean은 한국어 학습 서비스이다. 학습의 핵심은 **반복 연습과 즉각적인 피드백**이다.
클라우드 API만으로는 오프라인 환경, 응답 지연, 운영 비용 측면에서 한계가 있다.

**온디바이스 AI**를 도입하여 다음을 달성한다:

| 목표 | 설명 |
|------|------|
| **오프라인 학습** | 인터넷 없이 문법 교정, 대화 연습, 퀴즈 제공 |
| **즉시 응답** | 네트워크 지연 없는 실시간 피드백 (사용자 기기에서 직접 추론) |
| **비용 절감** | 간단한 요청을 온디바이스에서 처리하여 서버 API 호출량 대폭 감소 |
| **프라이버시** | 학습 데이터와 대화 내용이 사용자 기기를 떠나지 않음 |
| **파이프라인 보조** | 개발 파이프라인에서 로컬 LLM을 활용한 검증/리뷰 자동화 (§11.4) |

> 온디바이스 AI는 클라우드 API를 **대체**하는 것이 아니라 **보완**하는 구조이다. (§11.7 하이브리드 아키텍처 참조)

### 11.2 기술 스택

#### 11.2.1 BitNet.cpp (1비트 LLM 프레임워크)

| 항목 | 내용 |
|------|------|
| **개발** | Microsoft Research |
| **원리** | 가중치를 1.58비트 (삼진: -1, 0, +1)로 표현. 곱셈 대신 덧셈/뺄셈으로 추론 |
| **장점** | GPU 불필요 (CPU만으로 실행), 초경량 모델 크기, 극도로 낮은 전력 소비 |
| **현재 모델** | BitNet b1.58 2B4T — 2B 파라미터, ~400MB, ARM CPU 최적화 |
| **모바일 지원** | iOS/Android 네이티브 SDK 개발 중 (2026 로드맵) |
| **역할** | 항시 가동 경량 작업, 모바일 온디바이스 배포 |

#### 11.2.2 Ollama (범용 로컬 LLM)

| 항목 | 내용 |
|------|------|
| **원리** | llama.cpp 기반. FP16/Q4/Q8 양자화 모델을 GPU+CPU로 추론 |
| **장점** | 모델 다양 (2B~72B), 커뮤니티 생태계, OpenAI 호환 API |
| **현재 모델** | Qwen 2.5 72B, DeepSeek-R1 70B, Qwen3-Coder-30B 등 |
| **역할** | 고품질 코드 리뷰, 기획 교차 검증, 복잡한 학습 콘텐츠 생성 |

#### 11.2.3 역할 분담

| 용도 | BitNet.cpp | Ollama | 클라우드 API |
|------|-----------|--------|------------|
| 모바일 온디바이스 | **주력** | 사용 불가 (모델 크기) | 고품질 작업 시 |
| Mac Mini 항시 가동 | **주력** (경량 자동화) | 온디맨드 | - |
| 파이프라인 검증 | 품질 게이트 보조 | **주력** (교차 검증) | 최종 실행 |
| 학습 콘텐츠 생성 | 실시간 퀴즈/교정 | 고급 콘텐츠 생성 | **주력** |

### 11.3 Mac Mini 허브 아키텍처

Mac Mini M4 Pro (64GB RAM, 2TB SSD)를 온디바이스 AI의 **개발/검증/운영 허브**로 사용한다.

#### 11.3.1 리소스 레이어 구성

```
┌──────────────────── Mac Mini M4 Pro (64GB / 2TB) ────────────────────┐
│                                                                       │
│  ┌─ Layer 1: 항시 가동 (24/7) ──────────────────── ~3GB RAM ──────┐  │
│  │  OpenClaw Gateway    │  BitNet 2B (CPU)   │  모니터링/Runner    │  │
│  │  §5 메신저 연동      │  항시 대기 추론     │  GitHub Actions    │  │
│  └─────────────────────────────────────────────────────────────────┘  │
│                                                                       │
│  ┌─ Layer 2: 온디맨드 (개발 시간) ──────────────── ~35GB RAM ─────┐  │
│  │  Ollama (72B 모델)  │  Xcode + 시뮬레이터  │  Docker 샌드박스   │  │
│  │  교차 검증/리뷰      │  iOS 빌드/테스트    │  AI별 독립 환경    │  │
│  └─────────────────────────────────────────────────────────────────┘  │
│                                                                       │
│  ┌─ Layer 3: 실험 (여유 리소스) ────────────────── ~26GB RAM ─────┐  │
│  │  한국어 파인튜닝 실험  │  BitNet 대형 모델 테스트 (공개 시)      │  │
│  │  학습 콘텐츠 배치 생성 │  온디바이스 모델 품질 벤치마크          │  │
│  └─────────────────────────────────────────────────────────────────┘  │
└───────────────────────────────────────────────────────────────────────┘
```

#### 11.3.2 동시 실행 리소스 예산

| 워크로드 | CPU 코어 | RAM | 상태 |
|----------|---------|-----|------|
| OpenClaw Gateway | 1 | ~1GB | 항시 가동 |
| BitNet 2B | 1 | ~0.5GB | 항시 가동 |
| 모니터링 + Self-hosted Runner | 1 | ~1GB | 항시 가동 |
| Ollama (72B, Q4) | 4-6 | ~48GB | 온디맨드 |
| Xcode + iOS 시뮬레이터 | 4-6 | ~16GB | 온디맨드 |
| Docker 샌드박스 x2 (DB+Redis) | 2-4 | ~8GB | 온디맨드 |
| **최악 동시 사용 합계** | **14** | **~39GB** | 여유: ~25GB |

> Ollama 72B와 Xcode는 동시에 돌릴 수 있으나, 둘 다 피크 부하인 경우는 드물다.
> Layer 3 (실험)은 Layer 2가 유휴 상태일 때만 사용한다.

### 11.4 파이프라인 연계

온디바이스 AI를 기존 파이프라인 단계(§2)와 연계하여 개발 효율을 높인다.

#### 11.4.1 단계별 연계

| 파이프라인 단계 | 연계 도구 | 활용 방법 |
|---------------|----------|----------|
| **§2 검증** | Ollama (72B) | 기획 교차 검증. Claude가 세운 기획을 로컬 LLM이 독립 검증 (API 비용 $0) |
| **§5 리뷰** | Ollama (30B-Coder) | PR 코드 리뷰 보조. 중요 이슈만 Claude에게 재확인 |
| **§5 메신저** | BitNet 2B + OpenClaw | PR 요약, 빌드 결과 정리, 알림 메시지 생성 (항시 가동) |
| **§8 품질 게이트** | BitNet 2B | 커밋 메시지 컨벤션 검증, 시크릿 탐지, 변경 파일 요약 (pre-commit hook) |
| **§3.2 교차 검증** | Ollama (72B) | 복수 모델 교차 검증을 로컬에서 수행. §3.2의 Gemini/ChatGPT 역할 일부 대체 |

#### 11.4.2 품질 게이트 자동화 (BitNet)

BitNet 2B는 400MB로 항시 메모리에 상주하며, 다음 검증을 **즉시** 수행한다:

```
Git pre-commit hook
    ↓
BitNet 2B (CPU, <1초 응답)
    ↓
  ✓ 커밋 메시지 형식 검증 (Phase V1-2 : ... 또는 [Stage] TXXX: ...)
  ✓ diff 내 하드코딩된 시크릿 패턴 탐지 (API 키, 비밀번호 등)
  ✓ .env / credentials 파일 포함 여부 검사
  ✓ 변경 파일 요약 생성 (메신저 알림용)
    ↓
통과 → commit 진행
실패 → 경고 메시지 + commit 차단
```

### 11.5 학습 콘텐츠 온디바이스 제공

#### 11.5.1 온디바이스로 가능한 학습 기능

| 기능 | 설명 | 모델 | 오프라인 |
|------|------|------|---------|
| **문법 교정** | 학습자 입력 문장의 기본 문법 오류 교정 | BitNet 2B | O |
| **난이도 판별** | 문장/단어의 TOPIK 급수 판별 | BitNet 2B | O |
| **단어 퀴즈 생성** | 학습 진도에 맞는 단어 퀴즈 자동 생성 | BitNet 2B | O |
| **간단한 대화 연습** | 일상 대화 수준의 한국어 회화 파트너 | BitNet 2B | O |
| **관련 표현 추천** | 입력 문장과 관련된 표현/문형 제안 | BitNet 2B | O |
| **문법 상세 설명** | 복잡한 문법 규칙의 단계별 설명 | 서버 API | X |
| **작문 첨삭** | 장문 작문의 심층 첨삭 및 피드백 | 서버 API | X |
| **맞춤형 커리큘럼** | 학습자 수준에 맞는 커리큘럼 생성 | 서버 API | X |
| **TOPIK 모의시험 피드백** | 시험 답안에 대한 상세 피드백 | 서버 API | X |

#### 11.5.2 대화 연습 시나리오

```
[오프라인 환경 - 지하철에서]

학생: "오늘 날씨가 어때요?"
BitNet: "오늘은 맑아요. 산책하기 좋은 날이에요."
학생: "저도 산책을 하고 싶어요"
BitNet: "좋아요! 어디에서 산책하고 싶어요?"

→ TOPIK 1~2급 수준의 일상 대화
→ 인터넷 없이 즉시 응답
→ 대화 기록은 로컬 저장 → 온라인 시 서버 동기화
```

#### 11.5.3 온디바이스 모델의 한국어 능력 한계

| 항목 | BitNet 2B (현재) | 예상 (파인튜닝 후) | 서버 API |
|------|-----------------|-------------------|---------|
| 기본 문법 교정 | 보통 | 좋음 | 매우 좋음 |
| TOPIK 1~2급 대화 | 보통 | 좋음 | 매우 좋음 |
| TOPIK 3~4급 대화 | 부족 | 보통 | 좋음 |
| 복잡한 문법 설명 | 부족 | 부족 | 좋음 |
| 작문 첨삭 | 불가 | 부족 | 좋음 |

> **전략:** BitNet 2B의 한국어 능력이 제한적이므로, 한국어 학습 데이터로 **파인튜닝**하여 특정 작업의 품질을 끌어올린다. (§11.6 참조)

### 11.6 콘텐츠 파이프라인

학습 콘텐츠를 온디바이스 모델에 탑재하기 위한 파이프라인을 정의한다.

#### 11.6.1 콘텐츠 생성 흐름

```
┌────────────────────────────────────────────────────────────┐
│  1. 원본 콘텐츠 생성 (서버 / Mac Mini)                      │
│     - 클라우드 API (Claude)로 고품질 학습 데이터 생성        │
│     - 기존 코스/레슨 데이터에서 학습 패턴 추출               │
│     - TOPIK 기출문제, 문법 규칙 데이터셋 구축                │
├────────────────────────────────────────────────────────────┤
│  2. 데이터셋 가공 (Mac Mini)                                │
│     - 문법 교정 쌍 (오류 문장 → 교정 문장)                   │
│     - 대화 시나리오 (급수별 일상 대화 말뭉치)                 │
│     - 퀴즈 Q&A 쌍 (단어, 문법, 독해)                       │
│     - 난이도 레이블링 (TOPIK 1~6급)                         │
├────────────────────────────────────────────────────────────┤
│  3. 모델 파인튜닝 (Mac Mini / 클라우드 GPU)                  │
│     - BitNet 2B 기반 한국어 학습 특화 모델 생성              │
│     - 작업별 LoRA 어댑터: 문법교정, 대화, 퀴즈 각각 학습     │
│     - 품질 벤치마크 (Mac Mini에서 자동 평가)                 │
├────────────────────────────────────────────────────────────┤
│  4. 모델 배포 (앱 업데이트)                                  │
│     - 베이스 모델 (~400MB) + LoRA 어댑터 (~수십 MB)          │
│     - 앱 번들 또는 첫 실행 시 다운로드                       │
│     - 모델 버전 관리 (서버에서 최신 버전 확인)                │
└────────────────────────────────────────────────────────────┘
```

#### 11.6.2 데이터셋 구조

| 데이터셋 | 형식 | 예시 | 용량 (예상) |
|----------|------|------|-----------|
| 문법 교정 쌍 | `{input, corrected, rule}` | `{"나는 학교에 갔었다", "나는 학교에 갔다", "과거형 중복"}` | ~50MB |
| 대화 시나리오 | `{level, topic, turns[]}` | TOPIK 2급, 일상-날씨, 4턴 대화 | ~30MB |
| 퀴즈 Q&A | `{type, question, answer, level}` | 단어 의미, "사과"의 뜻?, 과일 이름, 1급 | ~20MB |
| 난이도 레이블 | `{sentence, level}` | "경제 성장률이 둔화되었다", 5급 | ~10MB |

#### 11.6.3 콘텐츠 업데이트 메커니즘

| 항목 | 방법 |
|------|------|
| **초기 탑재** | 앱 번들에 베이스 모델 + 기본 어댑터 포함 |
| **정기 업데이트** | 앱 업데이트 시 새 LoRA 어댑터 포함 |
| **온디맨드 업데이트** | 앱 내에서 "콘텐츠 업데이트" 버튼으로 새 어댑터 다운로드 |
| **버전 관리** | 서버 API에서 모델 버전 확인 → 구버전이면 업데이트 안내 |

### 11.7 하이브리드 아키텍처 (온디바이스 + 서버)

#### 11.7.1 요청 라우팅 전략

사용자 기기에서 요청 유형에 따라 **온디바이스 또는 서버로 자동 라우팅**한다.

```
┌─────────────────────────────────────────────────────────────┐
│  사용자 기기 (iPhone / Android)                               │
│                                                               │
│  [요청 발생]                                                  │
│      ↓                                                       │
│  [라우터] ─── 간단한 요청? ──→ 온디바이스 BitNet (즉시, 무료) │
│      │            │                                           │
│      │            ├─ 문법 교정                                 │
│      │            ├─ 단어 퀴즈                                 │
│      │            ├─ 난이도 판별                               │
│      │            └─ 간단한 대화                               │
│      │                                                        │
│      └─── 복잡한 요청? ──→ 서버 API (고품질, 과금)            │
│                  │                                            │
│                  ├─ 작문 첨삭                                  │
│                  ├─ 고급 문법 설명                              │
│                  ├─ 커리큘럼 생성                               │
│                  └─ TOPIK 피드백                               │
│                                                               │
│  [오프라인 감지] ──→ 모든 요청을 온디바이스로 처리              │
│                     (서버 전용 기능은 "온라인 시 이용 가능" 표시)│
└───────────────────┬───────────────────────────────────────────┘
                    ↓ (온라인 시)
          ┌──────────────────┐
          │ api.amazingkorean │
          │ .net              │
          └──────────────────┘
```

#### 11.7.2 라우팅 판단 기준

| 기준 | 온디바이스 | 서버 API |
|------|-----------|---------|
| 네트워크 상태 | 오프라인 또는 불안정 | 온라인 |
| 요청 복잡도 | 단순 (문법 교정, 퀴즈, 짧은 대화) | 복잡 (첨삭, 설명, 커리큘럼) |
| 입력 길이 | 짧은 문장 (~100자) | 긴 문장/글 (100자+) |
| 필요 품질 | 즉시성 > 정확성 | 정확성 > 즉시성 |
| 구독 상태 | 비구독자도 사용 가능 | 구독자만 사용 가능 |

> **비구독자 전략:** 온디바이스 기능은 **무료로 제공**하여 앱의 기본 가치를 체험하게 하고, 고급 기능(서버 API)은 구독 유도로 연결한다.

#### 11.7.3 데이터 동기화

| 데이터 | 저장 위치 | 동기화 |
|--------|----------|--------|
| 학습 진도 | 로컬 (SQLite) | 온라인 시 서버와 양방향 동기화 |
| 대화 기록 | 로컬 (SQLite) | 온라인 시 서버에 업로드 (선택적) |
| 퀴즈 결과 | 로컬 (SQLite) | 온라인 시 서버와 동기화 → 맞춤 커리큘럼 반영 |
| 모델/어댑터 | 로컬 (파일) | 서버에서 새 버전 다운로드 (수동) |

### 11.8 도입 로드맵

#### Phase A: Mac Mini 프로토타이핑 (Phase 3과 병행)

> **전제:** Mac Mini M4 Pro 확보 후 시작

| 단계 | 작업 | 산출물 |
|------|------|--------|
| A-1 | BitNet.cpp + Ollama 설치, 기본 실행 확인 | 설치 가이드 |
| A-2 | 한국어 학습 프롬프트 테스트 (문법 교정, 대화, 퀴즈) | 품질 벤치마크 리포트 |
| A-3 | REST API 래퍼 구축 → 프론트엔드(Web)에서 연동 테스트 | API 엔드포인트 |
| A-4 | 파이프라인 연계 테스트 (pre-commit hook, PR 요약) | 자동화 스크립트 |
| A-5 | 한국어 학습 데이터셋 초기 구축 | 데이터셋 v0.1 |

#### Phase B: 파인튜닝 및 품질 확보

| 단계 | 작업 | 산출물 |
|------|------|--------|
| B-1 | 한국어 학습 특화 데이터셋 확장 | 데이터셋 v1.0 |
| B-2 | BitNet 2B 한국어 파인튜닝 (LoRA) | 문법교정/대화/퀴즈 어댑터 |
| B-3 | 파인튜닝 모델 품질 벤치마크 | 벤치마크 리포트 (파인튜닝 전후 비교) |
| B-4 | 비용 분석: 온디바이스 vs 서버 API 비교 | 비용 분석 리포트 |

#### Phase C: 모바일 온디바이스 배포

> **전제:** BitNet.cpp iOS/Android SDK 출시 후 시작

| 단계 | 작업 | 산출물 |
|------|------|--------|
| C-1 | BitNet.cpp 모바일 SDK 평가 (§9.1 기준) | SDK 평가 리포트 |
| C-2 | iOS 프로토타입 (Mac Mini에서 Xcode 빌드) | iOS 앱 프로토타입 |
| C-3 | 하이브리드 라우팅 구현 (온디바이스 + 서버 API) | 라우팅 로직 |
| C-4 | 오프라인 모드 테스트 (비행기 모드에서 전체 기능 검증) | QA 리포트 |
| C-5 | 앱스토어/플레이스토어 배포 | 모바일 앱 v1.0 |

#### Phase D: 대형 모델 전환 (미래)

> **전제:** BitNet 7B+ 이상의 1비트 모델 공개 후

| 단계 | 작업 | 산출물 |
|------|------|--------|
| D-1 | 대형 BitNet 모델 품질 평가 | 2B vs 7B+ 비교 리포트 |
| D-2 | 모바일 실행 가능성 검증 (RAM, 속도, 배터리) | 모바일 벤치마크 |
| D-3 | 서버 API 의존 기능의 온디바이스 전환 판단 | 전환 범위 결정서 |
| D-4 | 온디바이스 전용 고급 기능 확장 (작문 첨삭, 상세 설명 등) | 기능 확장 기획서 |

#### 타임라인 (예상)

```
2026 Q1        현재. Mac Mini 확보 예정
        ├─ Phase A ─────────┤
2026 Q2                     ├─ Phase B ─────────┤
2026 Q3~                                         ├─ Phase C ──→ (SDK 출시 시점에 따라)
미정                                                             ├─ Phase D ──→
```

> **원칙:** 각 Phase는 이전 Phase의 산출물에 의존한다. SDK 미출시 등 외부 요인으로 Phase C가 지연되더라도, Phase A~B의 프로토타이핑과 데이터셋 구축은 독립적으로 진행한다.

### 11.9 한국어 발음 교정 AI 오케스트레이션

> 기능 스펙: [`AMK_API_MASTER.md §8.11`](./AMK_API_MASTER.md#811-한국어-발음-교정-ai-pronunciation-coaching-ai) 참조

#### 11.9.1 개요

발음 교정 AI는 4개의 독립 모듈(음소 평가, 피치 분석, 조음 가이드, 단음절 발음)로 구성된다.
각 모듈은 **서로 다른 AI/도구**가 담당하며, 파이프라인 §2의 기획→실행 흐름을 따른다.

#### 11.9.2 모듈별 AI 역할 배치

| 모듈 | 기획 (설계/연구) | 실행 (구현) | 검증 | 비고 |
|------|----------------|-----------|------|------|
| **① 음소 평가** | Claude (API 선정, 아키텍처) | Claude (백엔드 통합) + Whisper 파인튜닝 (Mac Mini) | Ollama (교차 검증) | 외부 API 연동 + 자체 모델 병행 |
| **② 피치 분석** | Claude (음성학 설계) | Claude (CREPE/pYIN 통합) | Mac Mini 벤치마크 | 온디바이스 완결, 서버 불필요 |
| **③ 조음 가이드** | Claude (음성학 DB 설계) + Gemini (다국어 교차 검증) | Claude (데이터 구축, UI) | 한국어 교육 전문가 수동 검증 | 정적 데이터, AI 추론 불필요 |
| **④ 단음절 발음** | Claude (녹음 스크립트, TTS 설계) | 전문 성우 녹음 (외주) + Claude (오디오 파이프라인) | 품질 샘플 테스트 | 사람 작업 비중 높음 |

#### 11.9.3 개발 파이프라인 흐름

```
┌─────────────────────────────────────────────────────────────────────┐
│  Phase P-1: 연구 및 프로토타이핑 (Mac Mini)                          │
│                                                                      │
│  [기획] Claude ──→ 전체 아키텍처 설계, API 후보 평가                   │
│  [검증] Ollama (72B) ──→ 설계 교차 검증 (로컬, API 비용 $0)          │
│  [실행] Mac Mini에서 프로토타입 구축:                                  │
│         ├─ SpeechSuper API 평가 (한국어 음소 정확도 테스트)            │
│         ├─ CREPE / pYIN 피치 분석 PoC (Python)                       │
│         ├─ Whisper 한국어 파인튜닝 환경 구축                          │
│         └─ 표준 발음 F0 프로필 측정 (librosa로 기준 데이터 생성)       │
│                                                                      │
│  산출물: 기술 검증 리포트, API 선정, F0 기준 데이터 v0.1              │
├─────────────────────────────────────────────────────────────────────┤
│  Phase P-2: 데이터 구축 (Mac Mini + 외주)                            │
│                                                                      │
│  [기획] Claude ──→ 데이터셋 스키마 설계, 녹음 스크립트 작성            │
│  [실행] 병렬 작업:                                                    │
│         ├─ Claude ──→ 조음 DB 구축 (19자음+21모음, 조음 위치 정의)    │
│         ├─ Claude ──→ 모국어별 오류 패턴 DB (음성학 문헌 기반)        │
│         ├─ 외주 ──→ 전문 성우 녹음 (~2,000음절 x 3속도)              │
│         └─ Mac Mini ──→ Whisper 파인튜닝 (AIHub 비원어민 데이터)      │
│  [검증] Gemini ──→ 조음 DB의 다국어 설명 교차 검증                    │
│                                                                      │
│  산출물: 조음 DB, 오류 패턴 DB, 녹음 파일, 파인튜닝 모델 v0.1        │
├─────────────────────────────────────────────────────────────────────┤
│  Phase P-3: 백엔드 통합 (§2 파이프라인 적용)                          │
│                                                                      │
│  [기획] Claude ──→ API 엔드포인트 설계, DTO 정의                      │
│  [실행] Claude ──→ Rust 백엔드 구현:                                  │
│         ├─ POST /pronunciation/assess (음소 평가)                     │
│         ├─ POST /pronunciation/pitch (피치 분석)                      │
│         ├─ GET /pronunciation/guide/{phoneme} (조음 가이드)           │
│         └─ GET /pronunciation/audio/{syllable} (단음절 발음)          │
│  [리뷰] Ollama (30B-Coder) ──→ 코드 리뷰                             │
│  [QA] 실제 비원어민 발화 샘플로 통합 테스트                            │
│                                                                      │
│  산출물: 백엔드 API 완성, QA 리포트                                   │
├─────────────────────────────────────────────────────────────────────┤
│  Phase P-4: 프론트엔드 + 모바일 통합                                  │
│                                                                      │
│  [기획] Claude ──→ UI/UX 설계 (피치 시각화, 조음 다이어그램)          │
│  [실행] 병렬:                                                         │
│         ├─ Claude ──→ Web 프론트엔드 (React)                          │
│         └─ TBD ──→ iOS/Android 네이티브 (온디바이스 통합)             │
│  [검증] 사용자 테스트 (실제 한국어 학습자 피드백)                      │
│                                                                      │
│  산출물: 발음 교정 기능 프로덕션 배포                                  │
└─────────────────────────────────────────────────────────────────────┘
```

#### 11.9.4 Mac Mini 역할 (발음 교정 전용)

| 작업 | 도구 | 리소스 | 시점 |
|------|------|--------|------|
| Whisper 파인튜닝 | Python + HuggingFace | GPU (M4 Pro), RAM ~16GB | Phase P-1~P-2 |
| F0 기준 데이터 생성 | librosa + CREPE | CPU, RAM ~4GB | Phase P-1 |
| SpeechSuper API 평가 | Python 스크립트 | 네트워크 | Phase P-1 |
| 조음 DB 품질 테스트 | Ollama (72B) | RAM ~48GB | Phase P-2 |
| 온디바이스 추론 벤치마크 | CREPE TF Lite / pYIN | CPU 전용 | Phase P-3 |

#### 11.9.5 온디바이스 vs 서버 분배

```
┌──────────────── 사용자 기기 (온디바이스) ────────────────┐
│                                                          │
│  피치 분석 (CREPE/pYIN)          → 완전 로컬, 실시간    │
│  조음 가이드 (룩업 테이블)        → 완전 로컬, 즉시     │
│  단음절 발음 (녹음 파일)          → 완전 로컬, 즉시     │
│  기본 음성 인식 (WhisperKit)      → 완전 로컬           │
│                                                          │
│  → 오프라인에서도 발음 연습 가능 (핵심 가치)             │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  정밀 음소 평가 (SpeechSuper)     → 서버 경유, 고품질   │
│  상세 교정 리포트                  → 서버 AI 생성        │
│  학습 진도 분석                    → 서버 API            │
│                                                          │
│  → 온라인 시 심화 피드백 제공                            │
└──────────────────────────────────────────────────────────┘
```

> **원칙:** 발음 연습의 핵심 루프(발음 → 피드백 → 교정 가이드 → 모범 발음 → 재시도)는 **온디바이스에서 완결**되어야 한다. 서버는 정밀도를 높이는 보조 역할이다.

[맨 위로](#목차-table-of-contents)
